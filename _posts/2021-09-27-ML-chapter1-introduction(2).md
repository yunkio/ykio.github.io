---
date: 2021-09-27
title: "Chapter 1. Introduction (2) - 확률론"
categories: 
  - 머신러닝과 패턴인식
tags: 
  - 머신러닝
  - 패턴인식
  - 확률
toc: true  
toc_sticky: true 
---
# 1.2 확률론
패턴 인식 분야에서 중요한 컨셉 중 하나는 **불확실성** 입니다. 불확실성은 측정할 때의 노이즈 및 제한된 데이터 집합 수 등에서 발생합니다. 확률론을 통해 불확실성을 계량화하고 조작하기 위한 이론적인 토대를 갖출 수 있습니다.

![image](/assets/images/ml/Figure1.9.png){: width="400"}{: .align-center} 
Figure 1.9 확률론 예시
{: style="text-align: center; font-size:0.7em;"}

위의 그림에서 랜덤하게 상자 하나를 골라 임의로 동그라미 하나를 꺼내고, 동그라미의 색을 확인한 후 꺼냈던 상자에다가 도로 집어 넣는다고 해보겠습니다. 이때 빨간색 상자를 고를 확률은 40%, 파란색 상자를 고를 확률은 60%이며 각각의 동그라미를 꺼낼 확률은 동일하다고 가정하겠습니다. 

이 예시에서 상자의 정체는 바로 확률 변수입니다. 앞으로 상자를 확률 변수 $B$라고 지칭하겠습니다. 이 확률 변수 $B$는 $r$(빨간색 상자)와 $b$(파란색 상자) 두 개의 값을 가질 수 있습니다. 동그라미 역시 확률 변수 $F$로 지칭할 것이며, 확률 변수 $F$는 $g$(초록색)과 $o$(오렌지색)를 값으로 가질 수 있습니다.

어떤 사건의 확률을 어떤 특정 사건이 일어나는 횟수를 전체 시도의 횟수로 나눈 것으로 정의하겠습니다. 이에 따라 $p(B = r) = 4/10$, $p(B=b)=6/10$ 이라고 적을 수 있습니다. 각각의 사건은 상호 배타적이며 각각의 사건들이 모든 가능한 결괏값을 포함할 경우 확률들의 합은 1입니다. 


## 합의 법칙과 곱의 법칙

이제 우리는 확률의 두 가지 기본 법칙인 **합의 법칙**과 **곱의 법칙**에 대해 살펴보겠습니다.

![image](/assets/images/ml/Figure1.10.png){: width="400"}{: .align-center} 
Figure 1.10 합의 법칙과 곱의 법칙을 설명하기 위한 그림
{: style="text-align: center; font-size:0.7em;"}

위의 예시에서는 $X$와 $Y$라는 두 가지 확률 변수가 있습니다. $X$는 $x_i(i = 1, ..., M)$ 중 아무 값이나 취할 수 있고, $Y$는 $y_j(j = 1, ..., L)$ 중 아무 값이나 취할 수 있다고 해보겠습니다. $X$와 $Y$ 각각에서 표본을 추출하는 시도를 $N$번 하며, $X=x_i$, $Y=y_i$인 시도의 개수를 $n_{ij}$라고 표현하겠습니다. 또한 $Y$의 값과 상관없이 $X=x_i$인 시도의 숫자를 $c_i$로, $Y=y_j$인 시도의 숫자를 $r_j$로 표현할 것입니다.

### 합의 법칙

$X$가 $x_i$, $Y$가 $y_j$일 확률을 $p(X=x_i,Y=y_j)$로 적고 이를 $X=x_i$, $Y=y_j$일 **결합 확률** 이라고 합니다. 이는 $i$, $j$ 칸에 있는 포인트의 숫자를 전체 포인트들의 숫자로 나눠서 구할 수 있습니다. 
$$p(X=x_i, Y=y_j) = \frac{n_{ij}}N$$

여기서 $\lim N \rightarrow \infty$ 를 가정했습니다. 비슷하게 $Y$값과 무관하게 $X$가 $x_i$값을 가질 확률을 $p(X = x_i)$로 적을 수 있습니다.

$$p(X = x_i) = \frac{c_i}N$$

앞서 살펴보았던 figure 1.10에서 $i$열에 있는 사례의 숫자는 해당 열의 각 칸에 있는 사례의 숫자 합입니다. 이는 $c_i = \sum_jn_{ij}$로 표현 가능합니다. 따라서 위 두 식으로 다음을 도출해 낼 수 있습니다.

$$p(X=x_i) = \sum^L_{j=1}p(X=x_i, Y=y_j)$$

이것이 바로 **합의 법칙**이며 $p(X=x_i)$는 **주변 확률** *marginal probability* 이라고 불립니다.

### 곱의 법칙

이제 $X = x_i$인 사례들만 고려해보겠습니다. 이 중에서 $Y=y_{ij}$인 사례들의 비율을 생각해 볼 수 있으며 이를 확률 $p(Y=y_j\vert X = x_i)$로 적을 수 있습니다. 이를 **조건부 확률** 이라고 부릅니다. 

$$p(Y=y_j|X=x_i) = \frac{n_{ij}}{c_i}$$

위와 같이 $i$ 행에 있는 전체 포인트의 수와 $i, j$칸에 있는 포인트 수의 비율을 통해 계산할 수 있으며, 이로부터  **곱의 법칙**을 도출해 낼 수 있습니다.

$$\begin{aligned} p(X=x_i,Y=y_i) &= \frac{n_{ij}}N = \frac{n_{ij}}{c_i} \cdot \frac{c_i}{N} \\ &= p(Y = y_j|X=x_i)p(X=x_i)\end{aligned}$$

위의 합의 법칙과 곱의 법칙을 더 간단한 표현법을 사용해서 표현할 수 있습니다.

$$p(X) = \sum_Yp(X, Y) \\ p(X, Y) = p(Y|X)p(X)$$
{: .notice}

## 베이즈 정리

위에서 구해낸 곱의 법칙을 활용하여 조건부 확률 간의 관계인 다음 식을 도출해낼 수 있습니다.

$$p(Y|X) = \frac{p(X|Y)p(Y)}{p(X)}$$

이 식이 머신 러닝과 패턴 인식 전반에 걸쳐 아주 중요한 역할을 차지하는 **베이즈 정리**입니다. 합의 법칙을 사용해서 베이지안 정리의 분모를 분자에 있는 항들로 표현할 수 있습니다.

$$p(X) = \sum_Yp(X|Y)p(Y)$$

베이지안 정리의 분모는 정규화 상수로 볼 수 있습니다. 왼쪽 항을 모든 $Y$값에 대하여 합했을 때 1이 되도록 하는 역할입니다.

<figure class="half">
  <a href="/assets/images/ml/Figure1.11a.png">
  <img src="/assets/images/ml/Figure1.11a.png"></a>

  <a href="/assets/images/ml/Figure1.11b.png">
  <img src="/assets/images/ml/Figure1.11b.png"></a>
</figure>
<figure class="half">
  <a href="/assets/images/ml/Figure1.11c.png">
  <img src="/assets/images/ml/Figure1.11c.png"></a>

  <a href="/assets/images/ml/Figure1.11d.png">
  <img src="/assets/images/ml/Figure1.11d.png"></a>
</figure>
Figure 1.11 두 변수의 결합 분포
{: style="text-align: center; font-size:0.7em;"}

이를 직관적으로 도식화한 그림이며, 두 변수의 결합 분포를 예로 들었습니다. 표본의 수는 $N=60$이며 표본들은 결합 분포에서 랜덤으로 추출했습니다. 분포에서 제한된 수의 데이터만 추출했을 때는 오른쪽 위의 그림과 같이 확률을 모델할 수 있습니다. 데이터로부터 원 분포를 모델링하는 것은 통계적 패턴 인식의 핵심 중 하나입니다.

### 예시

어떤 한 상자를 선택했는데 그것이 파란색 상자였다고 가정해보겠습니다. 그러면 그 상황에서 초록색 공을 고를 확률은 3/4이고 따라서 $p(F=a\vert B=b) = 3/4$ 입니다. 이와 같은 방법으로 경우의 수를 정리할 수 있으며, 확률의 합의 법칙과 곱의 법칙을 적용하여 초록색 공을 고를 전체 확률을 계산할 수 있습니다.

$$\begin{aligned} p(F=g) &= p(F=g|B=r)p(B=r) + p(F=g|B=b)p(B=b) \\ &= \frac14 \times \frac4{10} +  \frac34 \times \frac6{10} = \frac{11}{20} \end{aligned} $$

여기에 다시 합의 법칙을 적용하면 $p(F=o) = 1 - \frac{11}{20} = \frac{9}{20}$ 입니다.

이제 다른 예시를 들어보겠습니다. 어떤 공을 선택했는데 그 공이 오렌지색이고 이 오렌지색이 어떤 상자에서 나왔는지를 알고 싶다고 가정해 보겠습니다. 
이를 위해서는 공이 주어졌을 때 고른 상자가 어떤 것이었는지에 대한 조건부 확률을 계산해야 합니다. 베이지안 정리를 적용하여 조건부 확률을 뒤집으면 이 문제를 해결할 수 있습니다.

$$p(B=r|F=o) = \frac{p(F=o|B=r)p(B=r)}{p(F=o)} = \frac34\times\frac4{10}\times\frac{20}9 = \frac23$$

### 해석

베이지안 정리의 해석은 매우 중요합니다. 만약 어떤 공이 선택되었는지를 알기 전에 어떤 박스를 선택했는지에 대한 확률은 $p(B)$ 로 표현할 수 있습니다. 이를 **사전확률** *prior* 이라고 부릅니다. 어떤 공이 선택되었는지 관찰하기 전의 확률이기 때문입니다. 선택된 공이 오렌지색이라는 것을 알게 된다면 베이지안 정리를 활용하여 $p(B \vert F)$를 구할 수 있습니다. 이를 **사후 확률** *posterior* 이라고 부릅니다. 사건 $F$를 관측한 후의 확률이기 때문입니다.

이 예시에서 빨간색 상자를 고를 사전 확률은 4/10이므로 파란색 상자를 고를 확률이 더 높습니다. 하지만 선택된 공이 오렌지 색이라는 것을 확인하고 난 후엔 빨간색 상자를 고를 사후 확률이 2/3입니다. 따라서 이제는 우리가 고른 상자가 빨간색이었을 확률이 더 높습니다. 빨간색 상자 안의 오렌지색 공의 비율이 더 높으므로 오렌지색을 골랐다는 관측 결과가 고른 상자가 빨간색일 확률을 높여주는 것은 직관과도 일치하는 결과입니다. 

$p(X,Y) = p(X)p(Y)$인 경우를 고려해보겠습니다. 이처럼 각각의 주변 확률을 곱한 것이 결합 확률과 같을 경우 두 확률 변수를 **독립적**이라고 합니다. 이를 상자 예시에 적용해본다면, 만약 각각의 상자가 같은 수의 오렌지색 공과 초록색 공을 가지고 있다면 $p(F\vert B) = P(F)$가 됩니다. 

## 확률 밀도

### 확률밀도함수

![image](/assets/images/ml/Figure1.12.png){: width="400"}{: .align-center} 
Figure 1.12 확률 밀도 함수
{: style="text-align: center; font-size:0.7em;"}

이번에는 연속적인 변수에서의 확률을 알아보겠습니다. 만약 실수 변수 $x$가 $(x, x + \delta x)$ 구간 안의 값을 가지고 그 변수의 확률이 $p(x)\delta x(\delta x \rightarrow 0)$로 주어진다면, $p(x)$를 $x$의 **확률밀도**라고 부릅니다. 이때 $x$가 $(a,b)$구간 사이의 값을 가질 확률은 다음과 같습니다.
$$p(x \in (a,b)) = \int^b_ap(x)dx$$

확률은 양의 값을 가지고 $x$의 값은 실수축 상에 존재해야 하므로 확률 밀도 함수 $p(x)$는 다음의 두 조건을 만족해야 합니다.

$$\begin{aligned}p(x)\geqq0 \\ \int^\infty_{-\infty}p(x)dx = 1\end{aligned}$$

확률 분포 함수는 야코비안 인자로 인해서 비선형 변수 변환 시에 일반적인 단순 함수와는 다른 방식으로 변화합니다. 예를 들면 $x=g(y)$ 일 때 함수 $f(x)$는 $\tilde{f}(y)=f(g(y))$가 됩니다. $x$의 확률 밀도 함수 $p_x(x)$와 새로운 변수 $y$의 확률 밀도 함수 $p_y(y)$를 살펴보면 둘이 다른 확률 밀도를 가지는 것이 자명합니다. $(x, x + \delta x)$ 범위에 속하는 관찰값(아주 작은 $\delta x$에 대해)은 범위 $(y, y+\delta y)$로 변환됩니다. 이때 $p_x(x)\delta x \simeq p_y(y)\delta y$ 입니다. 따라서 다음과 같습니다.

$$\begin{aligned}p_y(y) &= p_x(x)\left|\frac{dx}{dy}\right|\\&=p_x(g(y))|g'(y)|\end{aligned}$$ 

따라서 확률 밀도의 최댓값은 어떤 변수를 선택하는 지에 따라 달라짐을 알 수 있습니다.

### 누적분포함수

$x$가 $(-\infty, z)$ 범위에 속할 확률은 **누적 분포 함수**로 표현됩니다. 

$$P(z) = \int^z_{-\infty}p(x)dx$$
Figure 1.12에서 보여진 것처럼 $P'(x) = p(x)$ 입니다. 만약 여러 개의 연속적인 변수 $x_1, ..., x_D$가 주어지고 이 변수들이 벡터 $\mathbf{x}$로 표현될 경우에 결합 확률 밀도 $p(\mathbf{x}) = p(x_1, ..., x_D)$로 정의할 수 있습니다. 이 확률밀도에서 $\mathbf{x}$가 포인트 $\mathbf{x}$를 포함한 극솟값 $\delta\mathbf{x}$에 포함될 확률은 $p(\mathbf{x})\delta\mathbf{x}$로 주어집니다. 이 다변량 확률 밀도는 다음의 조건을 만족해야 합니다.

$$\begin{aligned}p(\mathbf{x})\end{aligned} \geqq 0 \\ \int p(\mathbf{x})dx = 1$$
위의 식에서 적분은 전체 $x$ 공간에 대해 시행했습니다. 이때 $x$가 이산 변수인 경우 $p(x)$를 **확률 질량 함수** 라고 부릅니다. 확률 밀도 함수의 경우에도 합의 법칙, 곱의 법칙, 베이지안 정리가 적용됩니다. 

## 기댓값과 공분산

### 기댓값
확률 밀도 $p(x)$ 하에서 어떤 함수 $f(x)$의 평균값은 $f(x)$의 **기댓값**이라고 하며, $\mathbb{E}[f]$로 표현합니다. 각각 이산 분포와 연속 분포인 경우의 기댓값은 다음과 같습니다.

$$\begin{aligned}\mathbb{E}[f] = \sum_xp(x)f(x)\\\mathbb{E}[f]=\int p(x)f(x)dx\end{aligned}$$ 
이렇게 각 $x$값에 대해 해당 확률을 가중치로 가중 평균을 구합니다. 만약 유한한 $N$개의 포인트를 확률 분포 또는 확률 밀도에서 추출했다면, 각 포인트들의 유한한 합산으로 기댓값을 근사할 수 있습니다.

$$\mathbb{E}[f] \simeq \frac1N\sum^N_{n=1}f(x_n)$$

이때 $\lim N\rightarrow\infty$을 취했을 경우 정확한 값이 됩니다.

$$\mathbb{E}_x[f(x,y)]$$
어떤 변수에 대해 평균을 내는지 지정하여 계산할 수도 있습니다. 가령 위의 식의 경우 함수 $f(x,y)$의 평균값을 $x$의 분포에 대해 구하는 식입니다. 위 식은 $y$에 대한 함수가 됩니다.

또한 조건부 분포에 해당하는 **조건부 기댓값**을 구하는 식도 만들 수 있습니다.

$$\mathbb{E}[f|y] = \sum_xp(x|y)f(x)$$

### 분산
$f(x)$의 **분산**은 다음과 같이 정의됩니다.

$$\text{var}[f]=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])^2$$
분산은 $f(x)$가 평균값 $\mathbb{E}[f(x)]$로 부터 얼마나 멀리 분포되어 있는지를 나타냅니다. 위 식은 다음과 같이 $f(x)$와 $f(x)^2$의 기댓값으로 표현 가능합니다.

$$\text{var}[f] = \mathbb{E}[f(x)^2] - \mathbb{E}[f(x)]^2$$

### 공분산
두 개의 확률 변수 $x$와 $y$에 대해서 **공분산** *covariance*은 다음과 같이 정의됩니다.

$$\begin{aligned}\text{cov}[x,y] &= \mathbb{E}_{x,y}[\{x-\mathbb{E}[x]\}\{y-\mathbb{E}[y]\}]\\&=\mathbb{E}_{x,y}[xy]-\mathbb{E}[x]\mathbb{E}[y]\end{aligned}$$
공분산은 $x$값과 $y$값이 얼마나 함께 같이 변동하는가에 대한 지표입니다. 만약 $x$와 $y$가 독립일 경우 공분산값은 0으로 향합니다. 벡터 $\mathbf{x}$의 구성 원소들 서로 간의 공분산을 고려할 경우에는 $\text{cov}[\mathbf{x}]\equiv\text{cov}[\mathbf{x},\mathbf{x}]$와 같이 좀 더 간단하게 표현합니다.

## 베이지안 확률
지금까지의 확률을 '반복 가능한 임의의 사건의 빈도수' 라는 측면에서 살펴보는 해석을 **고전적** 또는 **빈도적** 관점이라고 부릅니다. 이보다 더 포괄적인 **베이지안** 관점에 대해서도 알아보도록 하겠습니다. 베이지안 관점을 활용하면 불확실성을 정량화할 수 있습니다. 주어진 상황의 불확실성을 정량화하고, 새 관측치가 주어질 때마다 불확실성을 수정하고 그 결과에 따라 최적의 선택을 제시하도록 돕는 방법론을 확률의 베이지안 해석이라고 부릅니다.

앞서 살펴보았던 다항식 곡성 피팅 예시를 다시 살펴보겠습니다. 베이지안 관점을 사용하면 $\mathbf{w}$와 같은 모델 매개변수의 불확실성을 설명할 수 있습니다. 데이터를 관측하기 전의 $\mathbf{w}$에 대한 우리의 가정을 사전 확률 분포 $p(\mathbf{w})$로 표현할 수 있습니다. 관측된 데이터 $\mathcal{D} = \{t_1, ..., t_N\}$은 조건부 확률 $p(\mathcal{D}\vert\mathbf{w})$로 작용합니다. 이 경우 베이지안 정리는 다음의 형태를 가집니다.

$$p(\mathbf{w}\vert\mathcal{D}) = \frac{p(\mathcal{D}|\mathbf{w})p(\mathbf{w})}{p(\mathcal{D})}$$

위 식은 $\mathcal{D}$를 관측한 후의 $\mathbf{w}$에 대한 불확실성을 사후 확률 $P(\mathbf{w}\vert\mathcal{D})$로 표현한 것입니다.  $p(\mathcal{D}\vert\mathbf{w})$는 관측 데이터 집합 $\mathcal{D}$를 바탕으로 계산됩니다. 이 값은 매개변수 벡터 $\mathbf{w}$의 함수로 볼 수 있으며, **가능도 함수** *likelihood function*라고 불립니다. 가능도 함수는 각각의 다른 매개변수 벡터 $\mathbf{w}$에 대해 관측된 데이터 집합이 '얼마나 그렇게 나타날 가능성이 있었는지'를 표현합니다. 확률분포가 아니므로 적분하여도 1이 될 필요가 없습니다.

가능도 함수에 대한 정의를 바탕으로 베이지안 정리를 '사후확률 $\propto$ 가능도 $\times$ 사전확률' 로 표현할 수 있습니다. 또 위에서 살펴보았던 식의 양쪽 변을 $\mathbf{w}$에 대하여 적분하면 베이지안 정리의 분모를 사전 확률과 가능도 함수로 표현할 수 있습니다.

$$p(\mathcal{D}) = \int p(\mathcal{D}\vert\mathbf{w})p(\mathbf{w})d\mathbf{w}$$

### 빈도적 확률 관점

빈도적 확률 관점에서는 $\mathbf{w}$가 고정된 매개변수로 여겨지며 추정에서의 오류는 데이터 집합들 $\mathcal{D}$의 분포를 고려함으로써 구합니다. 반면 이와 대조적으로 베이지안 확률 관점에서는 오직 하나의 데이터 집합 $\mathcal{D}$만이 존재하고 매개변수의 불확실성은 $\mathbf{w}$의 확률 분포를 통해 표현됩니다.

가령 빈도적 확률 관점에서는 **최대 가능도** 라는 추정값이 널리 사용됩니다. 최대 가능도를 사용할 경우 $\mathbf{w}$는 가능도 함수 $p(\mathcal{D}\vert\mathbf{w})$를 최대화하는 값으로 선택됩니다. 음의 로그 가능도 함숫값을 **오차 함수**라고 부릅니다.

### 베이지안 확률 관점

베이지안 확률 관점에서는 사전 지식을 추론 과정에 포함시킬 수 있습니다. 관측치가 치우친 값이 나오더라도 합리적인 사전확률을 사용하면 편향된 결과가 나오지 않습니다.

반면 주관적으로 사전 분포를 선택함으로써 실제 사전의 믿음을 반영하기보다는 수학적인 편리성을 위해 선택된다는 비판을 받기도 합니다. 좋지 않은 사전 분포를 바탕으로 한 베이지안 방법은 부족한 결과물을 내놓기 쉽습니다. 

## 가우시안 분포
**가우시안 분포**의 또 다른 이름은 **정규 분포**입니다. 가우시안 분포는 다음과 같이 정의됩니다.

$$\mathcal{N}(x\vert\mu,\sigma^2) = \frac{1}{(2\pi\sigma^2)^\frac{1}{2}}\exp\{-\frac{1}{2\sigma^2}(x-\mu)^2\}$$

위 식은 두 개의 매개변수 **평균** $\mu$와 **표준 편차** $\sigma$에 의해 통제됩니다. 또한 분산의 역수에 해당하는 $\beta = 1/\sigma^2$는 **정밀도**라고 합니다.
