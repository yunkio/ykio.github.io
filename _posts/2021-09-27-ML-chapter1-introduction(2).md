---
date: 2021-09-27
title: "Chapter 1. Introduction (2) - 확률론, 모델 선택"
categories: 
  - 머신러닝과 패턴인식
tags: 
  - 머신러닝
  - 패턴인식
  - 확률
toc: true  
toc_sticky: true 
---
# 1.2 확률론
패턴 인식 분야에서 중요한 컨셉 중 하나는 **불확실성** 입니다. 불확실성은 측정할 때의 노이즈 및 제한된 데이터 집합 수 등에서 발생합니다. 확률론을 통해 불확실성을 계량화하고 조작하기 위한 이론적인 토대를 갖출 수 있습니다.

![image](/assets/images/ml/Figure1.9.png){: width="400"}{: .align-center} 
Figure 1.9 확률론 예시
{: style="text-align: center; font-size:0.7em;"}

위의 그림에서 랜덤하게 상자 하나를 골라 임의로 동그라미 하나를 꺼내고, 동그라미의 색을 확인한 후 꺼냈던 상자에다가 도로 집어 넣는다고 해보겠습니다. 이때 빨간색 상자를 고를 확률은 40%, 파란색 상자를 고를 확률은 60%이며 각각의 동그라미를 꺼낼 확률은 동일하다고 가정하겠습니다. 

이 예시에서 상자의 정체는 바로 확률 변수입니다. 앞으로 상자를 확률 변수 $B$라고 지칭하겠습니다. 이 확률 변수 $B$는 $r$(빨간색 상자)와 $b$(파란색 상자) 두 개의 값을 가질 수 있습니다. 동그라미 역시 확률 변수 $F$로 지칭할 것이며, 확률 변수 $F$는 $g$(초록색)과 $o$(오렌지색)를 값으로 가질 수 있습니다.

어떤 사건의 확률을 어떤 특정 사건이 일어나는 횟수를 전체 시도의 횟수로 나눈 것으로 정의하겠습니다. 이에 따라 $p(B = r) = 4/10$, $p(B=b)=6/10$ 이라고 적을 수 있습니다. 각각의 사건은 상호 배타적이며 각각의 사건들이 모든 가능한 결괏값을 포함할 경우 확률들의 합은 1입니다. 


## 합의 법칙과 곱의 법칙

이제 우리는 확률의 두 가지 기본 법칙인 **합의 법칙**과 **곱의 법칙**에 대해 살펴보겠습니다.

![image](/assets/images/ml/Figure1.10.png){: width="400"}{: .align-center} 
Figure 1.10 합의 법칙과 곱의 법칙을 설명하기 위한 그림
{: style="text-align: center; font-size:0.7em;"}

위의 예시에서는 $X$와 $Y$라는 두 가지 확률 변수가 있습니다. $X$는 $x_i(i = 1, ..., M)$ 중 아무 값이나 취할 수 있고, $Y$는 $y_j(j = 1, ..., L)$ 중 아무 값이나 취할 수 있다고 해보겠습니다. $X$와 $Y$ 각각에서 표본을 추출하는 시도를 $N$번 하며, $X=x_i$, $Y=y_i$인 시도의 개수를 $n_{ij}$라고 표현하겠습니다. 또한 $Y$의 값과 상관없이 $X=x_i$인 시도의 숫자를 $c_i$로, $Y=y_j$인 시도의 숫자를 $r_j$로 표현할 것입니다.

### 합의 법칙

$X$가 $x_i$, $Y$가 $y_j$일 확률을 $p(X=x_i,Y=y_j)$로 적고 이를 $X=x_i$, $Y=y_j$일 **결합 확률** 이라고 합니다. 이는 $i$, $j$ 칸에 있는 포인트의 숫자를 전체 포인트들의 숫자로 나눠서 구할 수 있습니다. 
$$p(X=x_i, Y=y_j) = \frac{n_{ij}}N$$

여기서 $\lim N \rightarrow \infty$ 를 가정했습니다. 비슷하게 $Y$값과 무관하게 $X$가 $x_i$값을 가질 확률을 $p(X = x_i)$로 적을 수 있습니다.

$$p(X = x_i) = \frac{c_i}N$$

앞서 살펴보았던 figure 1.10에서 $i$열에 있는 사례의 숫자는 해당 열의 각 칸에 있는 사례의 숫자 합입니다. 이는 $c_i = \sum_jn_{ij}$로 표현 가능합니다. 따라서 위 두 식으로 다음을 도출해 낼 수 있습니다.

$$p(X=x_i) = \sum^L_{j=1}p(X=x_i, Y=y_j)$$

이것이 바로 **합의 법칙**이며 $p(X=x_i)$는 **주변 확률** *marginal probability* 이라고 불립니다.

### 곱의 법칙

이제 $X = x_i$인 사례들만 고려해보겠습니다. 이 중에서 $Y=y_{ij}$인 사례들의 비율을 생각해 볼 수 있으며 이를 확률 $p(Y=y_j\vert X = x_i)$로 적을 수 있습니다. 이를 **조건부 확률** 이라고 부릅니다. 

$$p(Y=y_j|X=x_i) = \frac{n_{ij}}{c_i}$$

위와 같이 $i$ 행에 있는 전체 포인트의 수와 $i, j$칸에 있는 포인트 수의 비율을 통해 계산할 수 있으며, 이로부터  **곱의 법칙**을 도출해 낼 수 있습니다.

$$\begin{aligned} p(X=x_i,Y=y_i) &= \frac{n_{ij}}N = \frac{n_{ij}}{c_i} \cdot \frac{c_i}{N} \\ &= p(Y = y_j|X=x_i)p(X=x_i)\end{aligned}$$

위의 합의 법칙과 곱의 법칙을 더 간단한 표현법을 사용해서 표현할 수 있습니다.

$$p(X) = \sum_Yp(X, Y) \\ p(X, Y) = p(Y|X)p(X)$$
{: .notice}

## 베이즈 정리

위에서 구해낸 곱의 법칙을 활용하여 조건부 확률 간의 관계인 다음 식을 도출해낼 수 있습니다.

$$p(Y|X) = \frac{p(X|Y)p(Y)}{p(X)}$$

이 식이 머신 러닝과 패턴 인식 전반에 걸쳐 아주 중요한 역할을 차지하는 **베이즈 정리**입니다. 합의 법칙을 사용해서 베이지안 정리의 분모를 분자에 있는 항들로 표현할 수 있습니다.

$$p(X) = \sum_Yp(X|Y)p(Y)$$

베이지안 정리의 분모는 정규화 상수로 볼 수 있습니다. 왼쪽 항을 모든 $Y$값에 대하여 합했을 때 1이 되도록 하는 역할입니다.

<figure class="half">
  <a href="/assets/images/ml/Figure1.11a.png">
  <img src="/assets/images/ml/Figure1.11a.png"></a>

  <a href="/assets/images/ml/Figure1.11b.png">
  <img src="/assets/images/ml/Figure1.11b.png"></a>
</figure>
<figure class="half">
  <a href="/assets/images/ml/Figure1.11c.png">
  <img src="/assets/images/ml/Figure1.11c.png"></a>

  <a href="/assets/images/ml/Figure1.11d.png">
  <img src="/assets/images/ml/Figure1.11d.png"></a>
</figure>
Figure 1.11 두 변수의 결합 분포
{: style="text-align: center; font-size:0.7em;"}

이를 직관적으로 도식화한 그림이며, 두 변수의 결합 분포를 예로 들었습니다. 표본의 수는 $N=60$이며 표본들은 결합 분포에서 랜덤으로 추출했습니다. 분포에서 제한된 수의 데이터만 추출했을 때는 오른쪽 위의 그림과 같이 확률을 모델할 수 있습니다. 데이터로부터 원 분포를 모델링하는 것은 통계적 패턴 인식의 핵심 중 하나입니다.

### 예시

이번 글의 맨 앞에서 살펴보았던 상자를 예시로 들어보겠습니다. 어떤 한 상자를 선택했는데 그것이 파란색 상자였다고 가정해보겠습니다. 그러면 그 상황에서 초록색 공을 고를 확률은 3/4이고 따라서 $p(F=a\vert B=b) = 3/4$ 입니다. 이와 같은 방법으로 경우의 수를 정리할 수 있으며, 확률의 합의 법칙과 곱의 법칙을 적용하여 초록색 공을 고를 전체 확률을 계산할 수 있습니다.

$$\begin{aligned} p(F=g) &= p(F=g|B=r)p(B=r) + p(F=g|B=b)p(B=b) \\ &= \frac14 \times \frac4{10} +  \frac34 \times \frac6{10} = \frac{11}{20} \end{aligned} $$

여기에 다시 합의 법칙을 적용하면 $p(F=o) = 1 - \frac{11}{20} = \frac{9}{20}$ 입니다.

이제 다른 예시를 들어보겠습니다. 어떤 공을 선택했는데 그 공이 오렌지색이고 이 오렌지색이 어떤 상자에서 나왔는지를 알고 싶다고 가정해 보겠습니다. 
이를 위해서는 공이 주어졌을 때 고른 상자가 어떤 것이었는지에 대한 조건부 확률을 계산해야 합니다. 베이지안 정리를 적용하여 조건부 확률을 뒤집으면 이 문제를 해결할 수 있습니다.

$$p(B=r|F=o) = \frac{p(F=o|B=r)p(B=r)}{p(F=o)} = \frac34\times\frac4{10}\times\frac{20}9 = \frac23$$

### 해석

베이지안 정리의 해석은 매우 중요합니다. 만약 어떤 공이 선택되었는지를 알기 전에 어떤 박스를 선택했는지에 대한 확률은 $p(B)$ 로 표현할 수 있습니다. 이를 **사전확률** *prior* 이라고 부릅니다. 어떤 공이 선택되었는지 관찰하기 전의 확률이기 때문입니다. 선택된 공이 오렌지색이라는 것을 알게 된다면 베이지안 정리를 활용하여 $p(B \vert F)$를 구할 수 있습니다. 이를 **사후 확률** *posterior* 이라고 부릅니다. 사건 $F$를 관측한 후의 확률이기 때문입니다.

이 예시에서 빨간색 상자를 고를 사전 확률은 4/10이므로 파란색 상자를 고를 확률이 더 높습니다. 하지만 선택된 공이 오렌지 색이라는 것을 확인하고 난 후엔 빨간색 상자를 고를 사후 확률이 2/3입니다. 따라서 이제는 우리가 고른 상자가 빨간색이었을 확률이 더 높습니다. 빨간색 상자 안의 오렌지색 공의 비율이 더 높으므로 오렌지색을 골랐다는 관측 결과가 고른 상자가 빨간색일 확률을 높여주는 것은 직관과도 일치하는 결과입니다. 

$p(X,Y) = p(X)p(Y)$인 경우를 고려해보겠습니다. 이처럼 각각의 주변 확률을 곱한 것이 결합 확률과 같을 경우 두 확률 변수를 **독립적**이라고 합니다. 이를 상자 예시에 적용해본다면, 만약 각각의 상자가 같은 수의 오렌지색 공과 초록색 공을 가지고 있다면 $p(F\vert B) = P(F)$가 됩니다. 

## 확률 밀도

### 확률밀도함수

![image](/assets/images/ml/Figure1.12.png){: width="400"}{: .align-center} 
Figure 1.12 확률 밀도 함수
{: style="text-align: center; font-size:0.7em;"}

이번에는 연속적인 변수에서의 확률을 알아보겠습니다. 만약 실수 변수 $x$가 $(x, x + \delta x)$ 구간 안의 값을 가지고 그 변수의 확률이 $p(x)\delta x(\delta x \rightarrow 0)$로 주어진다면, $p(x)$를 $x$의 **확률밀도**라고 부릅니다. 이때 $x$가 $(a,b)$구간 사이의 값을 가질 확률은 다음과 같습니다.
$$p(x \in (a,b)) = \int^b_ap(x)dx$$

확률은 양의 값을 가지고 $x$의 값은 실수축 상에 존재해야 하므로 확률 밀도 함수 $p(x)$는 다음의 두 조건을 만족해야 합니다.

$$\begin{aligned}p(x)\geqq0 \\ \int^\infty_{-\infty}p(x)dx = 1\end{aligned}$$

확률 분포 함수는 야코비안 인자로 인해서 비선형 변수 변환 시에 일반적인 단순 함수와는 다른 방식으로 변화합니다. 예를 들면 $x=g(y)$ 일 때 함수 $f(x)$는 $\tilde{f}(y)=f(g(y))$가 됩니다. $x$의 확률 밀도 함수 $p_x(x)$와 새로운 변수 $y$의 확률 밀도 함수 $p_y(y)$를 살펴보면 둘이 다른 확률 밀도를 가지는 것이 자명합니다. $(x, x + \delta x)$ 범위에 속하는 관찰값(아주 작은 $\delta x$에 대해)은 범위 $(y, y+\delta y)$로 변환됩니다. 이때 $p_x(x)\delta x \simeq p_y(y)\delta y$ 입니다. 따라서 다음과 같습니다.

$$\begin{aligned}p_y(y) &= p_x(x)\left|\frac{dx}{dy}\right|\\&=p_x(g(y))|g'(y)|\end{aligned}$$ 

따라서 확률 밀도의 최댓값은 어떤 변수를 선택하는 지에 따라 달라짐을 알 수 있습니다.

### 누적분포함수

$x$가 $(-\infty, z)$ 범위에 속할 확률은 **누적 분포 함수**로 표현됩니다. 

$$P(z) = \int^z_{-\infty}p(x)dx$$

Figure 1.12에서 보여진 것처럼 $P'(x) = p(x)$ 입니다. 만약 여러 개의 연속적인 변수 $x_1, ..., x_D$가 주어지고 이 변수들이 벡터 $\mathbf{x}$로 표현될 경우에 결합 확률 밀도 $p(\mathbf{x}) = p(x_1, ..., x_D)$로 정의할 수 있습니다. 이 확률밀도에서 $\mathbf{x}$가 포인트 $\mathbf{x}$를 포함한 극솟값 $\delta\mathbf{x}$에 포함될 확률은 $p(\mathbf{x})\delta\mathbf{x}$로 주어집니다. 이 다변량 확률 밀도는 다음의 조건을 만족해야 합니다.

$$\begin{aligned}p(\mathbf{x})\end{aligned} \geqq 0 \\ \int p(\mathbf{x})dx = 1$$

위의 식에서 적분은 전체 $x$ 공간에 대해 시행했습니다. 이때 $x$가 이산 변수인 경우 $p(x)$를 **확률 질량 함수** 라고 부릅니다. 확률 밀도 함수의 경우에도 합의 법칙, 곱의 법칙, 베이지안 정리가 적용됩니다. 

## 기댓값과 공분산

### 기댓값
확률 밀도 $p(x)$ 하에서 어떤 함수 $f(x)$의 평균값은 $f(x)$의 **기댓값**이라고 하며, $\mathbb{E}[f]$로 표현합니다. 각각 이산 분포와 연속 분포인 경우의 기댓값은 다음과 같습니다.

$$\begin{aligned}\mathbb{E}[f] = \sum_xp(x)f(x)\\\mathbb{E}[f]=\int p(x)f(x)dx\end{aligned}$$ 

이렇게 각 $x$값에 대해 해당 확률을 가중치로 가중 평균을 구합니다. 만약 유한한 $N$개의 포인트를 확률 분포 또는 확률 밀도에서 추출했다면, 각 포인트들의 유한한 합산으로 기댓값을 근사할 수 있습니다.

$$\mathbb{E}[f] \simeq \frac1N\sum^N_{n=1}f(x_n)$$

이때 $\lim N\rightarrow\infty$을 취했을 경우 정확한 값이 됩니다.

$$\mathbb{E}_x[f(x,y)]$$

어떤 변수에 대해 평균을 내는지 지정하여 계산할 수도 있습니다. 가령 위의 식의 경우 함수 $f(x,y)$의 평균값을 $x$의 분포에 대해 구하는 식입니다. 위 식은 $y$에 대한 함수가 됩니다.

또한 조건부 분포에 해당하는 **조건부 기댓값**을 구하는 식도 만들 수 있습니다.

$$\mathbb{E}[f|y] = \sum_xp(x|y)f(x)$$

### 분산
$f(x)$의 **분산**은 다음과 같이 정의됩니다.

$$\text{var}[f]=\mathbb{E}[(f(x)-\mathbb{E}[f(x)])^2]$$

분산은 $f(x)$가 평균값 $\mathbb{E}[f(x)]$로 부터 얼마나 멀리 분포되어 있는지를 나타냅니다. 위 식은 다음과 같이 $f(x)$와 $f(x)^2$의 기댓값으로 표현 가능합니다.

$$\text{var}[f] = \mathbb{E}[f(x)^2] - \mathbb{E}[f(x)]^2$$

### 공분산
두 개의 확률 변수 $x$와 $y$에 대해서 **공분산** *covariance*은 다음과 같이 정의됩니다.

$$\begin{aligned}\text{cov}[x,y] &= \mathbb{E}_{x,y}[\{x-\mathbb{E}[x]\}\{y-\mathbb{E}[y]\}]\\&=\mathbb{E}_{x,y}[xy]-\mathbb{E}[x]\mathbb{E}[y]\end{aligned}$$

공분산은 $x$값과 $y$값이 얼마나 함께 같이 변동하는가에 대한 지표입니다. 만약 $x$와 $y$가 독립일 경우 공분산값은 0으로 향합니다. 벡터 $\mathbf{x}$의 구성 원소들 서로 간의 공분산을 고려할 경우에는 $\text{cov}[\mathbf{x}]\equiv\text{cov}[\mathbf{x},\mathbf{x}]$와 같이 좀 더 간단하게 표현합니다.

## 베이지안 확률
지금까지의 확률을 '반복 가능한 임의의 사건의 빈도수' 라는 측면에서 살펴보는 해석을 **고전적** 또는 **빈도적** 관점이라고 부릅니다. 이보다 더 포괄적인 **베이지안** 관점에 대해서도 알아보도록 하겠습니다. 베이지안 관점을 활용하면 불확실성을 정량화할 수 있습니다. 주어진 상황의 불확실성을 정량화하고, 새 관측치가 주어질 때마다 불확실성을 수정하고 그 결과에 따라 최적의 선택을 제시하도록 돕는 방법론을 확률의 베이지안 해석이라고 부릅니다.

앞서 살펴보았던 다항식 곡성 피팅 예시를 다시 살펴보겠습니다. 베이지안 관점을 사용하면 $\mathbf{w}$와 같은 모델 매개변수의 불확실성을 설명할 수 있습니다. 데이터를 관측하기 전의 $\mathbf{w}$에 대한 우리의 가정을 사전 확률 분포 $p(\mathbf{w})$로 표현할 수 있습니다. 관측된 데이터 $\mathcal{D} = \{t_1, ..., t_N\}$은 조건부 확률 $p(\mathcal{D}\vert\mathbf{w})$로 작용합니다. 이 경우 베이지안 정리는 다음의 형태를 가집니다.

$$p(\mathbf{w}\vert\mathcal{D}) = \frac{p(\mathcal{D}|\mathbf{w})p(\mathbf{w})}{p(\mathcal{D})}$$

위 식은 $\mathcal{D}$를 관측한 후의 $\mathbf{w}$에 대한 불확실성을 사후 확률 $P(\mathbf{w}\vert\mathcal{D})$로 표현한 것입니다.  $p(\mathcal{D}\vert\mathbf{w})$는 관측 데이터 집합 $\mathcal{D}$를 바탕으로 계산됩니다. 이 값은 매개변수 벡터 $\mathbf{w}$의 함수로 볼 수 있으며, **가능도 함수** *likelihood function*라고 불립니다. 가능도 함수는 각각의 다른 매개변수 벡터 $\mathbf{w}$에 대해 관측된 데이터 집합이 '얼마나 그렇게 나타날 가능성이 있었는지'를 표현합니다. 확률분포가 아니므로 적분하여도 1이 될 필요가 없습니다.

가능도 함수에 대한 정의를 바탕으로 베이지안 정리를 '사후확률 $\propto$ 가능도 $\times$ 사전확률' 로 표현할 수 있습니다. 또 위에서 살펴보았던 식의 양쪽 변을 $\mathbf{w}$에 대하여 적분하면 베이지안 정리의 분모를 사전 확률과 가능도 함수로 표현할 수 있습니다.

$$p(\mathcal{D}) = \int p(\mathcal{D}\vert\mathbf{w})p(\mathbf{w})d\mathbf{w}$$

### 빈도적 확률 관점

빈도적 확률 관점에서는 $\mathbf{w}$가 고정된 매개변수로 여겨지며 추정에서의 오류는 데이터 집합들 $\mathcal{D}$의 분포를 고려함으로써 구합니다. 반면 이와 대조적으로 베이지안 확률 관점에서는 오직 하나의 데이터 집합 $\mathcal{D}$만이 존재하고 매개변수의 불확실성은 $\mathbf{w}$의 확률 분포를 통해 표현됩니다.

가령 빈도적 확률 관점에서는 **최대 가능도** 라는 추정값이 널리 사용됩니다. 최대 가능도를 사용할 경우 $\mathbf{w}$는 가능도 함수 $p(\mathcal{D}\vert\mathbf{w})$를 최대화하는 값으로 선택됩니다. 머신러닝 분야에서는 음의 로그 가능도 함숫값을 **오차 함수**라고 부릅니다. 음의 로그 함수는 단조 감소하는 함수이기 때문에 가능도의 최댓값을 찾는 것이 오차를 최소화 하는 것과 같습니다.

### 베이지안 확률 관점

베이지안 확률 관점에서는 사전 지식을 추론 과정에 포함시킬 수 있습니다. 관측치가 치우친 값이 나오더라도 합리적인 사전확률을 사용하면 편향된 결과가 나오지 않습니다.

반면 주관적으로 사전 분포를 선택함으로써 실제 사전의 믿음을 반영하기보다는 수학적인 편리성을 위해 선택된다는 비판을 받기도 합니다. 좋지 않은 사전 분포를 바탕으로 한 베이지안 방법은 부족한 결과물을 내놓기 쉽습니다. 

## 가우시안 분포

### 가우시안 분포의 성질

![image](/assets/images/ml/Figure1.13.png){: width="400"}{: .align-center} 
Figure 1.13 가우시안 분포 도식
{: style="text-align: center; font-size:0.7em;"}

**가우시안 분포**의 또 다른 이름은 **정규 분포**입니다. 가우시안 분포는 다음과 같이 정의됩니다.

$$\mathcal{N}(x\vert\mu,\sigma^2) = \frac{1}{(2\pi\sigma^2)^\frac{1}{2}}\exp\{-\frac{1}{2\sigma^2}(x-\mu)^2\}$$

위 식은 두 개의 매개변수 **평균** $\mu$와 **표준 편차** $\sigma$에 의해 통제됩니다. 또한 분산의 역수에 해당하는 $\beta = 1/\sigma^2$는 **정밀도**라고 합니다.

식으로부터 가우시안 분포가 만족하는 성질들을 알 수 있습니다. 가우시안 분포는 정규화 되어있고 앞서 살펴보았던 확률 밀도의 두가지 조건을 만족합니다.  

$$\begin{aligned}\mathbb{E}[x] = \int^\infty_{-\infty}\mathcal{N}(x\vert\mu,\sigma^2)xdx = \mu\end{aligned} \\ \mathbb{E}[x^2] = \int^\infty_{-\infty}\mathcal{N}(x\vert\mu,\sigma^2)x^2dx = \mu^2 + \sigma^2 \\
\text{var}[x] = \mathbb{E}[x^2]-\mathbb{E}[x]^2 = \sigma^2$$

또한 가우시안 분포를 따르는 임의의 $x$에 대한 기댓값을 구할 수 있으며, 평균값 매개변수 $\mu$가 $x$의 기댓값과 동일함을 확인할 수 있습니다.  $x^2$의 기대값을 구한 뒤 두 식을 활용하여 계산하면 $x$의 분산이 $\sigma^2$인 것을 확인할 수 있습니다. 분포의 최댓값을 **최빈값**이라고 하는데, 가우시안 분포의 경우에는 최빈값과 평균값이 같습니다.

### 연속 분포의 가우시안 

$$\mathcal{N}(\mathbf{x}\vert\mu,\Sigma) = \frac{1}{(2\pi)^{D/2}}\frac{1}{\lvert \Sigma\rvert^{1/2}}\exp\{-\frac12(\mathbf{x}-\mu)^\text{T}\Sigma^{-1}(\mathbf{x}-\mu)\}$$

위 식은 연속 변수로 이루어진 $D$차원의 벡터 $\mathbf{x}$에 대한 가우시안 분포입니다. $D$차원 벡터 $\mu$는 평균값, $D\times D$ 행렬 $\Sigma$는 공분산 입니다. 또한 $\lvert \Sigma \rvert$는 $\Sigma$의 행렬식입니다. 이제 다변량 가우시안 분포에 대해서 간단하게 살펴보겠습니다. 

관측된 데이터 $\mathbf{X} = \{x_1, ..., x_N\}^\text{T}$를 살펴보겠습니다. 관측된 $N$개의 스칼라 변수 $x$를 의미합니다. 평균값 $\mu$와 분산 $\sigma^2$를 가지는 가우시안 분포에서 관측값들을 독립적으로 추출한다고 가정하겠습니다. 이를 **독립적이고 동일하게 분포** *i.i.d* 되었다고 말합니다. 두 독립 사건의 결합 확률은 각 사건의 주변 확률의 곱이므로 조건부 확률을 다음과 같이 적을 수 있습니다.

$$ p(\mathsf{x}\vert\mu, \sigma^2) = \prod^N_{n=1}\mathcal{N}(x_n\vert\mu,\sigma^2)$$

이 식은 가우시안 분포의 가능도 함수에 해당합니다. 다음 그림은 이를 도식화 한 것입니다. 

![image](/assets/images/ml/Figure1.14.png){: width="400"}{: .align-center} 
Figure 1.14 가우시안 분포의 가능도 함수
{: style="text-align: center; font-size:0.7em;"}

### 최대 가능도 함수

우리는 관측된 데이터 집합을 바탕으로 가능도 함수를 최대화하는 매개변수를 찾을 수 있습니다. 로그 함수는 변수에 대해 단조 증가하므로 로그를 취한 후 최댓값을 찾는 것이 원래 함수의 최댓값을 찾는 것과 같습니다. 

$$\ln p(\mathsf{x}\vert\mu,\sigma^2) = -\frac{1}{2\sigma^2}\sum^N_{n = 1}(x_n - \mu)^2 - \frac{N}{2}\ln\sigma^2 - \frac{N}{2}\ln(2\pi)$$

$\mu$에 대해 위 식의 최댓값을 찾으면 다음의 최대 가능도 해($\mu_{\text{ML}}$)를 찾을 수 있습니다. 또한, $\sigma^2$에 대해 최댓값을 찾으면 분산에 대한 최대 가능도 해도 찾을 수 있습니다.

$$\mu_{\text{ML}} = \frac{1}{N}\sum^N_{n=1}x_n\\ \sigma^2_{\text{ML}} = \frac1N\sum^N_{n=1}(x_n-\mu_{\text{ML}})^2$$

위 식은 관찰된 값 $\{x_n\}$들의 평균인 **표본 평균**이며, 밑 값은 표뵨 평균에 대해 계산된 **표본 분산**입니다. 이와 같은 최대 가능도 방법은 구조적으로 분포의 분산을 과소평가하는 문제가 있습니다. 이는 **편향** *bias*라 불리는 현상의 예시로, 과적합 문제와 연관이 있습니다.  최대 가능도 해인 $\mu_{\text{ML}}$와 $\sigma^2_{\text{ML}}$는 데이터 집합의 $x_1, ..., x_N$의 함수입니다. 각 데이터 집합의 값에 대해 기댓값을 구하면 각각 $\mu$, $\left(\frac{N-1}{N}\right)\sigma^2$가 나옵니다. 따라서 평균은 올바르게 구할 수 있지만 분산은 $\frac{(N-1)}{N}$만큼 과소평가됩니다.

데이터의 개수인 $N$이 커질수록 편향치는 점점 줄어들게 됩니다. $\lim N\rightarrow\infty$의 경우 아예 같아집니다. 실제 적용 사례에서는 데이터의 개수가 아주 작은 경우가 아니라면 큰 문제가 되지는 않습니다. 하지만 매개변수가 많아지고 모델이 복잡해질수록 문제가 커집니다. 이 편향 문제는 과적합 문제의 근본적인 원인이 됩니다.

## 곡선 피팅
앞서서 오차 촤소화의 측면에서 살펴보았던 다항식 곡선 피팅 문제를 확률적 측면에서 살펴보겠습니다. $N$개의 입력값 $\mathsf{x}=(x_1, ..., x_N)^\text{T}$와 해당 표적값 $\mathsf{t} = (t_1, ..., t_N)^\text{T}$ 가 주어진 상황에서 새로운 입력 변수 $x$의 타깃 변수 $t$를 예측해내는 문제입니다. 확률 분포를 사용해 타깃 변수의 값에 대한 불확실성을 표현할 수 있습니다. 우선 주어진 $x$값에 대한 $t$값이 $y(x, \mathbf{w})$를 평균으로 가지는 가우시안 분포를 가진다고 가정하겠습니다. 이를 바탕으로 조건부 분포를 적을 수 있습니다.

$$p(t\vert x, \mathbf{w}, \beta) = \mathcal{N} (t\vert y(x,\mathbf{w},\beta^{-1})$$

![image](/assets/images/ml/Figure1.16.png){: width="400"}{: .align-center} 
Figure 1.16 가우시안 조건부 분포식
{: style="text-align: center; font-size:0.7em;"}

식을 도식화한 것이 위의 그림입니다. 이제 훈련 집합 $\{\mathsf{x},\mathsf{t}\}$를 바탕으로 최대 가능도 방법을 이용하여 알려지지 않은 매개변수 $\mathbf{w}$와 $\beta$를 구해보겠습니다. 데이터가 위의 식에서 독립적으로 추출되었다면 가능도 함수는 다음과 같습니다.

$$p(\mathsf{t}\vert\mathsf{x}, \mathbf{w}, \beta) = \prod^N_{n=1}\mathcal{N}(t_n\vert y(x_n,\mathbf{w}),\beta^{-1} \\ \ln p(\mathsf{t}\vert\mathsf{x}, \mathbf{w}, \beta) = -\frac\beta2\sum^N_{n=1}\{y(x_n,\mathbf{w})-t_n\}^2 + \frac N2\ln\beta-\frac N2\ln(2\pi)$$

우선 다항식 계수의 최대 가능도 해 $\mathbf{w}_{\text{ML}}$를 구해보겠습니다. 마지막 두 항은 $\mathbf{w}$와 관련없으므로 제외할 수 있고, 로그 가능도에 양의 상수를 곱해도 $\mathbf{w}$에 대한 최댓값의 위치는 변하지 않으므로 맨 앞의 계수를 1/2로 바꿀 수 있습니다. 마지막으로 로그 가능도를 최대화하는 대신에 로그 가능도의 음의 값을 취한 후 이를 최소화할 수 있습니다. 결과적으로 $\mathbf{w}$를 구하는 경우에는 간으도 함수를 최대화하는 것과 제곱합 오차 함수를 최소화 하는 것이 결국 같습니다. 

마찬가지로 $\beta$를 결정하는 데도 최대 가능도 방법을 사용해보겠습니다. 위 식을 $\beta$에 대해 최대화하면 다음과 같습니다.

$$\frac1{\beta_\text{ML}}=\frac1N\sum^N_{n=1}\{y(x_n,\mathbf{w}_{\text{ML}})-t_n\}^2$$

이제 $\mathbf{w}, \beta$를 바탕으로 새로운 변수 $x$에 대한 예측값을 구할 수 있습니다. 지금은 확률 모델을 사용하고 있으므로 예측값은 $t$에 대한 **예측 분포**로 표현됩니다. 

$$p(t\vert x,\mathbf{w}_{\text{ML}},\beta_\text{ML}) = \mathcal{N} (t\vert y(x,\mathbf{w}_{\text{ML}}),\beta^{-1}_\text{ML})$$

### 최대 사후 분포 *MAP*

이제 베이지안 방식으로 문제를 해결하기 위해 다항 계수 $\mathbf{w}$에 대한 사전 분포를 도입하겠습니다. 문제의 단순화를 위해 다음 형태를 지닌 가우시안 분포를 사용하겠습니다.

$$p(\mathbf{w}\vert\alpha) = \mathcal{N}(\mathbf{w}\vert0,\alpha^{-1}\mathbf{I}) = \left(\frac\alpha{2\pi}\right)^{(M+1)/2}\exp\{-\frac\alpha2\mathbf{w}^\text{T}\mathbf{w}\}$$

여기서 $\alpha$는 분포의 정밀도이며, $M+1$은 $M$차수 다항식 벡터 $\mathbf{w}$의 원소의 개수입니다. $\alpha$와 같이 매개변수의 분포를 제어하는 변수를 **초매개변수** *hyper parameter*라고 합니다. 베이지안 정리에 따라 $\mathbf{w}$의 사후 분포는 사전 분포와 가능도 함수의 곱에 비례합니다.

$$p(\mathbf{w}\vert\mathsf{x},\mathsf{t},\alpha,\beta)\propto p(\mathsf{t}\vert\mathsf{x},\mathbf{w},\beta)p(\mathbf{w},\alpha)$$

이제 주어진 데이터에 대해 가장 가능성 높은 $\mathbf{w}$를 찾으면 문제를 해결하게 됩니다. 이처럼 사후 분포를 최대화하는 방향으로 답을 찾는 방식을 **최대 사후 분포** *maximum posterior, MAP* 이라고 합니다. 위 식을 앞서서 살펴 보았던 식에 음의 로그를 취하면 곧 다음 식과 같습니다.

$$\frac\beta2\sum^N_{n=1}\{y(x_n,\mathbf{w})-t_n\}^2 + \frac\alpha2\mathbf{w}^\text{T}\mathbf{w}$$ 

즉 사후 분포를 최대화하는 것이 정규화 매개변수가 $\lambda = \alpha/\beta$로 주어진 식의 정규화된 제곱합 오차 함수를 최소화하는 것과 동일합니다.

## 베이지안 곡선 피팅

사전 분포를 활용했지만 완전한 베이지안적 접근을 위해서는 모든 $\mathbf{w}$에 대해서 적분을 시행하여 확률의 합의 법칙과 곱의 법칙을 일관적으로 적용해야 합니다. 이러한 **주변화**가 패턴 인식에서의 베이지안 방법론의 핵심입니다. 곡선 피팅 문제의 목표를 위해 예측 분포 $p(t\vert x, \mathsf{x}, \mathsf{t})$를 구해보겠습니다. $\alpha, \beta$는 고정되어 있다고 가정하고 생략하겠습니다.

$$ p(t\vert x, \mathsf{x}, \mathsf{t}) = \int p(t\vert x,\mathbf{w})p(\mathbf{w}\vert\mathsf{x},\mathsf{t})d\mathbf{w}$$

$p(\mathbf{w}\vert\mathsf{x},\mathsf{t})$는 매개변수들에 대한 사후분포입니다. 위 식을 적분하면 예측 분포가 다음과 같이 가우시안 분포로 주어지게 됩니다.

$$p(\mathsf{t}\vert x,\mathsf{x},\mathsf{t}) = \mathcal{N}\left(t\vert m(x),s^2(x)\right) $$

위 식에서 평균과 분산은 다음과 같습니다.

$$ m(x) = \beta\phi(x)^\text{T}\mathbf{S}\sum^N_{n=1}\phi(x_n)t_n \\ s^2(x) = \beta^{-1} + \phi(x)^\text{T}\mathbf{S}\phi(x)$$

여기서 행렬 $\mathbf{S}$는 다음과 같습니다.

$$\mathbf{S}^{-1} = \alpha\mathbf{I}+\beta\sum^N _{n=1}\phi(x_n)\phi(x_n)^\text{T}$$

$\mathbf{I}$는 단위행렬이며 $\phi(x)$는 각각의 원소가 $i = 0, ..., M$에 대해 $\phi_i(x) = x^i$인 벡터 입니다.

![image](/assets/images/ml/Figure1.17.png){: width="400"}{: .align-center} 
Figure 1.17 $M=9$ 다항식 곡선 피팅 문제의 예측 분포
{: style="text-align: center; font-size:0.7em;"}

위 그림은 위에서 구한 식을 그림으로 나타낸 것입니다. 예측 분포의 평균과 분산은 $x$에 종속되어 있으며, 타깃 변수의 노이즈로 인한 예측값 $t$의 불확실성이 분산식의 첫번째 항에 표현되어 있습니다. 또한 분산식의 두 번째 항은 $\mathbf{w}$의 불확실성으로부터 기인한 것이며 베이지안 접근법으로 구해진 것입니다. 

# 1.3 모델 선택

앞선 예시에서 가장 좋은 일반화 값을 주는 모델의 복잡도가 있다는 것을 알아보았습니다. 우리는 모델의 복잡도를 잘 조절해야하며, 또한 매개변수들의 값을 잘 결정해야 합니다. 뿐만 아니라 다양한 모델을 고려하여 가장 적합한 모델을 선택해야 합니다. 이를 위한 몇가지 방법이 있습니다.

## 검증 집합

데이터가 충분할 경우 일부의 데이터만 사용하여 다양한 모델과 매개변수들을 훈련시키고 독립적인 데이터 집합인 **검증 집합**에서 비교/선택할 수 있습니다. 이런 경우 세 번째의 **시험 집합**을 따로 준비해서 이 집합으로 최종 성능을 판단하는 것이 좋을 수 있습니다. 

하지만 대부분의 실제 경우 데이터의 공급이 제한적이므로 가능한 한 많은 데이터를 활용할 필요가 있습니다.

## 교차 검증법
![image](/assets/images/ml/Figure1.18.png){: width="400"}{: .align-center} 
Figure 1.18 교차 검증법
{: style="text-align: center; font-size:0.7em;"}

최대한 많은 데이터를 활용하여 학습하면서 동시에 충분한 크기의 검증 집합을 가질 수 있는 방법입니다.  전체 데이터($S$) 중 데이터의 $(S-1)/S$ 비율만큼 훈련에 사용하고, 모든 데이터를 다 활용하여 성능을 추정합니다. 데이터가 부족할 경우에는 $S=N$의 방법도 고려할 수 있으며 이를 **leave-one-out** 테크닉이라고 합니다.

교차검증법의 단점은 $S$의 수가 늘어남에 따라 모델 훈련에 많은 시간이 든다는 것입니다. 훈련 자체가 계산적으로 복잡할수록 더 큰 문제가 됩니다. 또한 여러 매개변수들의 조합을 확인해 보기 위해서는 기하급수적인 수의 훈련이 필요하게 됩니다. 

## 정보 기준

앞서 말한 방법들의 단점을 극복하기 위해서는 오직 훈련 집합만을 활용하며, 과적합으로 인한 편향으로부터 자유로운 척도가 필요합니다. 역사적으로 다양한 **정보 기준** *information criteria* 들이 대안으로 제시되었습니다. 복잡한 모델에서 과적합을 방지하도록 페널티항을 추가하는 방법입니다. 예를 들면 **아카이케의 정보량 기준** *AIC*가 있습니다.

$$ \ln p(\mathcal{D}\vert\mathbf{w}_\text{ML})-M$$

여기서 $p(\mathcal{D}\vert\mathbf{w}_\text{ML})$은 잘 피팅된 로그 가능도이며 $M$은 수정 가능한 매개변수의 숫자입니다. **베이지안 정보 기준** *BIC*는 AIC의 약간 변형된 버전입니다. 이러한 기준들은 매개변수들의 불확실성을 고려하지 않으며 과하게 간단한 모델을 선택하는 경향이 있습니다.